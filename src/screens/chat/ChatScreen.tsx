import React, { useState, useEffect, useRef } from 'react';
import {
  View,
  Text,
  StyleSheet,
  ScrollView,
  TouchableOpacity,
  TextInput,
} from 'react-native';
import { Video, Audio, ResizeMode } from 'expo-av';
import { LinearGradient } from 'expo-linear-gradient';
import { useSafeAreaInsets } from 'react-native-safe-area-context';
import { colors, typography, spacing, borderRadius } from '../../theme';
import SpeechBubble from '../../components/ui/SpeechBubble';
import MicrophoneButton from '../../components/ui/MicrophoneButton';
import TypewriterText from '../../components/ui/TypewriterText';
import { useMicrophone } from '../../hooks/useMicrophone';
import { ChatMessage } from '../../types';
import { triggerHapticFeedback } from '../../utils/haptics';
import { useLanguage } from '../../context/LanguageContext';
import { generateAIResponse, ChatMessage as AIChatMessage } from '../../utils/aiChat';
import { speakSpanish, stopSpeaking } from '../../utils/textToSpeech';

export default function ChatScreen({ navigation }: any) {
  const { t } = useLanguage();
  const { 
    listening, 
    startListening, 
    startListeningWithAutoStop,
    stopListening, 
    transcript,
    hasPermission,
    requestPermission,
  } = useMicrophone();
  const insets = useSafeAreaInsets();
  const videoRef = useRef<Video>(null);
  const standingVideoRef = useRef<Video>(null);
  const [currentVideo, setCurrentVideo] = useState<'hola' | 'standing'>('hola');
  const [holaVideoSource, setHolaVideoSource] = useState<any>(null);
  const [standingVideoSource, setStandingVideoSource] = useState<any>(null);
  const [holaVideoReady, setHolaVideoReady] = useState(false);
  const [standingVideoReady, setStandingVideoReady] = useState(false);
  const [showGreeting, setShowGreeting] = useState(false);
  const [showGreetingPart2, setShowGreetingPart2] = useState(false);
  const [hasStartedRecording, setHasStartedRecording] = useState(false);
  const [userTranscription, setUserTranscription] = useState<string>('');
  const [messages, setMessages] = useState<ChatMessage[]>([]);
  const [inputText, setInputText] = useState('');
  const [isGeneratingResponse, setIsGeneratingResponse] = useState(false);
  const [apiError, setApiError] = useState<string | null>(null);
  const lastSentMessageRef = React.useRef<string>('');
  const greetingTimerRef = React.useRef<NodeJS.Timeout | null>(null);
  const holaPlayedRef = React.useRef<boolean>(false);
  const holaStartTimeRef = React.useRef<number | null>(null);

  // V√©rifier la configuration de l'API au d√©marrage
  React.useEffect(() => {
    const checkApiKey = () => {
      const apiKey = process.env.EXPO_PUBLIC_OPENAI_API_KEY || '';
      if (!apiKey || apiKey.trim() === '') {
        setApiError('Cl√© API OpenAI non configur√©e. V√©rifiez votre fichier .env et red√©marrez le serveur.');
        console.error('‚ùå OPENAI_API_KEY is not configured');
        console.error('‚ùå Please check:');
        console.error('   1. Create a .env file in the project root');
        console.error('   2. Add: EXPO_PUBLIC_OPENAI_API_KEY=your_api_key_here');
        console.error('   3. Restart the Expo server (npm start)');
      } else {
        setApiError(null);
        console.log('‚úÖ OPENAI_API_KEY is configured (length:', apiKey.length, ')');
      }
    };
    checkApiKey();
  }, []);

  // Charger les deux vid√©os
  useEffect(() => {
    const setupVideos = async () => {
      try {
        // Configurer le mode audio
        await Audio.setAudioModeAsync({
          allowsRecordingIOS: false,
          playsInSilentModeIOS: true,
          staysActiveInBackground: false,
          shouldDuckAndroid: false,
          playThroughEarpieceAndroid: false,
        });

        // Charger les deux vid√©os
        const holaSource = require('../../assets/media/videos/hola.mp4');
        const standingSource = require('../../assets/media/videos/call_standing.mp4');
        setHolaVideoSource(holaSource);
        setStandingVideoSource(standingSource);
        setCurrentVideo('hola');
        console.log('‚úÖ Videos loaded (hola and standing)');
      } catch (error) {
        console.error('Error setting up videos:', error);
      }
    };
    setupVideos();
  }, []);

  // Cacher le texte de salutation quand on passe √† standing
  useEffect(() => {
    if (currentVideo === 'standing') {
      setShowGreeting(false);
      setShowGreetingPart2(false);
    }
  }, [currentVideo]);

  // Faire dispara√Ætre le texte si l'utilisateur n'a pas encore appuy√© sur record
  useEffect(() => {
    // Si l'utilisateur a appuy√© sur record, le texte reste visible
    if (hasStartedRecording) {
      return;
    }
    // Si l'utilisateur n'a pas encore appuy√© sur record, le texte dispara√Æt apr√®s 3 secondes
    if (showGreeting && !hasStartedRecording) {
      const hideTimer = setTimeout(() => {
        setShowGreeting(false);
        console.log('‚úÖ Greeting text hidden (user has not pressed record)');
      }, 3000); // Dispara√Æt apr√®s 3 secondes si pas d'interaction

      return () => clearTimeout(hideTimer);
    }
  }, [showGreeting, hasStartedRecording]);

  // Lancer imm√©diatement la vid√©o standing quand on passe √† 'standing'
  useEffect(() => {
    if (currentVideo === 'standing' && standingVideoReady && standingVideoRef.current) {
      console.log('‚ñ∂Ô∏è Launching standing video immediately');
      standingVideoRef.current.setIsMutedAsync(true);
      standingVideoRef.current.setVolumeAsync(0);
      standingVideoRef.current.playAsync();
    }
  }, [currentVideo, standingVideoReady]);

  // Fonction pour g√©n√©rer une r√©ponse de l'IA en espagnol
  const getAIResponse = React.useCallback(async (userMessage: string): Promise<string> => {
    try {
      setIsGeneratingResponse(true);
      
      // Construire l'historique de conversation en alternant user/assistant
      const conversationHistory: AIChatMessage[] = [];
      
      // Parcourir les messages dans l'ordre et construire l'historique
      for (const msg of messages.slice(-10)) { // Garder seulement les 10 derniers messages
        conversationHistory.push({
          role: msg.isUser ? 'user' : 'assistant',
          content: msg.text,
        });
      }
      
      // Appeler l'API OpenAI
      const aiResponse = await generateAIResponse(userMessage, conversationHistory);
      return aiResponse;
    } catch (error) {
      console.error('‚ùå Error getting AI response:', error);
      // Retourner une r√©ponse de fallback
      return '¬øQu√© m√°s quieres decir?';
    } finally {
      setIsGeneratingResponse(false);
    }
  }, [messages]);

  const handleSend = React.useCallback(async (textToSend?: string) => {
    const text = textToSend || inputText || transcript;
    if (text && typeof text === 'string' && text.trim()) {
      // √âviter le double envoi
      if (lastSentMessageRef.current === text.trim()) {
        console.log('‚ö†Ô∏è Message d√©j√† envoy√©, ignor√©');
        return;
      }
      
      lastSentMessageRef.current = text.trim();
      
      // Afficher la transcription de l'utilisateur en haut
      setUserTranscription(text.trim());
      setShowGreeting(false); // Cacher le texte "Hola, ¬øc√≥mo est√°s?"
      setShowGreetingPart2(false);
      
      // Ajouter le message utilisateur √† l'historique
      const userMessage: ChatMessage = {
        id: Date.now().toString(),
        text: text.trim(),
        isUser: true,
        timestamp: new Date(),
      };
      setMessages(prev => [...prev, userMessage]);
      setInputText('');
      
      // G√©n√©rer une r√©ponse de l'IA en espagnol
      try {
        const aiResponseText = await getAIResponse(text.trim());
        
        // Si la r√©ponse contient une erreur de configuration, l'afficher
        if (aiResponseText.includes('non configur√©e') || aiResponseText.includes('not configured')) {
          setApiError(aiResponseText);
        } else {
          setApiError(null);
        }
        
        // Ajouter la r√©ponse de l'IA √† l'historique
        const aiMessage: ChatMessage = {
          id: (Date.now() + 1).toString(),
          text: aiResponseText,
          isUser: false,
          timestamp: new Date(),
        };
        setMessages(prev => [...prev, aiMessage]);
        
        // Afficher la r√©ponse de l'IA en haut
        setUserTranscription(aiResponseText);
        
        // Faire parler Sofia √† voix haute en espagnol
        await speakSpanish(aiResponseText, true);
      } catch (error: any) {
        console.error('‚ùå Error in handleSend:', error);
        const errorMessage = error?.message || 'Lo siento, hubo un error. ¬øPuedes repetir?';
        
        // Si c'est une erreur de configuration API, l'afficher clairement
        if (errorMessage.includes('non configur√©e') || errorMessage.includes('not configured')) {
          setApiError(errorMessage);
        }
        
        // Afficher un message d'erreur
        setUserTranscription(errorMessage);
        // Parler le message d'erreur aussi
        await speakSpanish(errorMessage, false);
      }
    }
  }, [inputText, transcript, getAIResponse]);

  // Fonction de validation pour l'arr√™t automatique (envoie automatiquement le message)
  const validateAndSend = React.useCallback(async (transcribedText: string | undefined | null): Promise<boolean> => {
    console.log('üîç ChatScreen validateAndSend called with:', transcribedText);
    if (transcribedText && typeof transcribedText === 'string' && transcribedText.trim().length > 0) {
      console.log('‚úÖ Valid text found, sending message and stopping recording');
      // Envoyer automatiquement le message
      handleSend(transcribedText);
      return true; // Arr√™ter l'enregistrement
    }
    console.log('‚è≥ No valid text yet, continuing recording');
    return false; // Continuer si pas de texte
  }, [handleSend]);

  // Arr√™ter le micro et la synth√®se vocale quand on quitte l'√©cran
  React.useEffect(() => {
    return () => {
      if (listening) {
        console.log('üõë ChatScreen unmounting: stopping microphone');
        stopListening().catch(err => console.error('Error stopping mic on unmount:', err));
      }
      // Arr√™ter toute synth√®se vocale en cours
      stopSpeaking();
      // Nettoyer le timer de salutation
      if (greetingTimerRef.current) {
        clearTimeout(greetingTimerRef.current);
        greetingTimerRef.current = null;
      }
    };
  }, [listening, stopListening]);

  const handleMicrophonePress = async () => {
    console.log('üé§ ChatScreen handleMicrophonePress called, listening:', listening);
    
    // Marquer que l'utilisateur a commenc√© √† enregistrer et r√©afficher le texte
    if (!hasStartedRecording) {
      setHasStartedRecording(true);
      // R√©afficher le texte de salutation si l'utilisateur appuie sur record
      if (!showGreeting) {
        setShowGreeting(true);
      }
    }
    
    if (listening) {
      // Arr√™ter manuellement
      console.log('‚èπÔ∏è Stopping recording manually');
      try {
        const transcribedText = await stopListening();
        if (transcribedText && typeof transcribedText === 'string' && transcribedText.trim().length > 0) {
          handleSend(transcribedText);
        }
      } catch (error) {
        console.error('‚ùå Error stopping recording:', error);
      }
    } else {
      console.log('‚ñ∂Ô∏è Starting recording...');
      // V√©rifier la permission
      if (!hasPermission) {
        console.log('‚ö†Ô∏è No permission, requesting...');
        const granted = await requestPermission();
        if (!granted) {
          console.log('‚ùå Permission not granted');
          return;
        }
      }
      
      console.log('‚úÖ Permission OK, starting with auto-stop');
      // D√©marrer avec validation automatique (envoie automatiquement quand il y a du texte)
      try {
        await startListeningWithAutoStop(validateAndSend);
        console.log('‚úÖ Recording started successfully');
      } catch (error) {
        console.error('‚ùå Error starting recording:', error);
      }
    }
  };

  return (
    <View style={styles.container}>
      {/* Vid√©os en arri√®re-plan avec fondu */}
      <View style={styles.videoWrapper}>
        {/* Vid√©o hola.mp4 */}
        {holaVideoSource && currentVideo === 'hola' && (
          <View style={[styles.videoContainer, { zIndex: 1 }]}>
            <Video
              ref={videoRef}
              source={holaVideoSource}
              style={[styles.backgroundVideo, !holaVideoReady && styles.videoHidden]}
              shouldPlay={holaVideoReady}
              isLooping={false}
              resizeMode={ResizeMode.COVER}
              useNativeControls={false}
              isMuted={true}
              volume={0}
              progressUpdateIntervalMillis={100}
              onLoadStart={() => {
                console.log('üé¨ Hola video load started');
                setHolaVideoReady(false);
                // R√©initialiser le timer de d√©marrage
                holaStartTimeRef.current = null;
                // R√©initialiser les √©tats du texte
                setShowGreeting(false);
                setShowGreetingPart2(false);
                // Nettoyer le timer de texte s'il existe
                if (greetingTimerRef.current) {
                  clearTimeout(greetingTimerRef.current);
                  greetingTimerRef.current = null;
                }
              }}
              onLoad={(status) => {
                console.log('‚úÖ Hola video loaded:', status);
                setHolaVideoReady(true);
                // Garder la vid√©o en muet pour √©viter le doublon avec ElevenLabs
                videoRef.current?.setIsMutedAsync(true);
                videoRef.current?.setVolumeAsync(0);
                videoRef.current?.playAsync();
              }}
              onError={(error) => {
                console.error('‚ùå Hola video error:', error);
                setHolaVideoReady(false);
              }}
              onPlaybackStatusUpdate={(status) => {
                if (status.isLoaded) {
                  // D√©tecter quand la vid√©o commence √† jouer pour d√©clencher le timer du texte
                  if (status.isPlaying && holaStartTimeRef.current === null) {
                    holaStartTimeRef.current = Date.now();
                    console.log('‚ñ∂Ô∏è Hola video started playing, starting greeting timer');
                    // Afficher "Hola" apr√®s 1 seconde
                    greetingTimerRef.current = setTimeout(() => {
                      setShowGreeting(true);
                      console.log('‚úÖ "Hola" displayed');
                      // Afficher "¬øc√≥mo est√°s?" apr√®s 2 secondes suppl√©mentaires
                      setTimeout(() => {
                        setShowGreetingPart2(true);
                        console.log('‚úÖ "¬øc√≥mo est√°s?" displayed');
                        // Faire parler Sofia : "Hola, ¬øc√≥mo est√°s?"
                        speakSpanish('Hola, ¬øc√≥mo est√°s?', true).catch(err => {
                          console.error('‚ùå Error speaking greeting:', err);
                        });
                      }, 2000);
                    }, 1000);
                  }
                  
                  // Si la vid√©o hola est termin√©e, passer directement √† call_standing
                  if (status.didJustFinish && !holaPlayedRef.current) {
                    console.log('‚úÖ Hola video finished, switching to call_standing');
                    holaPlayedRef.current = true;
                    // Nettoyer le timer si la vid√©o se termine avant que le texte n'apparaisse
                    if (greetingTimerRef.current) {
                      clearTimeout(greetingTimerRef.current);
                      greetingTimerRef.current = null;
                    }
                    // Arr√™ter la vid√©o hola imm√©diatement
                    videoRef.current?.pauseAsync();
                    // Passer √† standing - la vid√©o est d√©j√† en train de jouer en arri√®re-plan
                    setCurrentVideo('standing');
                  }
                  if (!status.isPlaying && !status.isBuffering && holaVideoReady && !status.didJustFinish) {
                    videoRef.current?.playAsync();
                  }
                  // Garder la vid√©o en muet pour √©viter le doublon avec ElevenLabs
                  if (!status.isMuted) {
                    videoRef.current?.setIsMutedAsync(true);
                    videoRef.current?.setVolumeAsync(0);
                  }
                }
              }}
            />
          </View>
        )}

        {/* Vid√©o call_standing.mp4 - pr√©charg√©e et jou√©e en arri√®re-plan pour transition instantan√©e */}
        {standingVideoSource && (
          <View style={[styles.videoContainer, styles.standingVideoContainer, currentVideo !== 'standing' && styles.videoBehind]}>
            <Video
              ref={standingVideoRef}
              source={standingVideoSource}
              style={styles.backgroundVideo}
              shouldPlay={standingVideoReady}
              isLooping={true}
              resizeMode={ResizeMode.COVER}
              useNativeControls={false}
              isMuted={true}
              volume={0}
              progressUpdateIntervalMillis={100}
              onLoadStart={() => {
                console.log('üé¨ Standing video load started');
                setStandingVideoReady(false);
              }}
              onLoad={(status) => {
                console.log('‚úÖ Standing video loaded:', status);
                setStandingVideoReady(true);
                // Lancer imm√©diatement la vid√©o en arri√®re-plan
                standingVideoRef.current?.setIsMutedAsync(true);
                standingVideoRef.current?.setVolumeAsync(0);
                standingVideoRef.current?.playAsync();
              }}
              onError={(error) => {
                console.error('‚ùå Standing video error:', error);
                setStandingVideoReady(false);
              }}
              onPlaybackStatusUpdate={(status) => {
                if (status.isLoaded) {
                  // Si la vid√©o se termine, la relancer automatiquement
                  if (status.didJustFinish) {
                    console.log('üîÑ Standing video finished, restarting loop');
                    standingVideoRef.current?.setPositionAsync(0);
                    standingVideoRef.current?.playAsync();
                  }
                  // Si la vid√©o n'est pas en train de jouer et n'est pas en train de charger, la relancer (toujours en arri√®re-plan)
                  if (!status.isPlaying && !status.isBuffering && standingVideoReady && !status.didJustFinish) {
                    standingVideoRef.current?.playAsync();
                  }
                  if (!status.isMuted) {
                    standingVideoRef.current?.setIsMutedAsync(true);
                    standingVideoRef.current?.setVolumeAsync(0);
                  }
                }
              }}
            />
          </View>
        )}
      </View>

      {/* Overlay l√©ger pour am√©liorer la lisibilit√© */}
      <View style={styles.overlay} />
      
      {/* Masquer toute bordure multicolore */}
      <View style={styles.borderMask} />

      <View style={[styles.content, { paddingTop: insets.top }]}>
        {/* Header */}
        <View style={styles.header}>
          <TouchableOpacity 
            onPress={() => {
              triggerHapticFeedback();
              navigation.navigate('CallEnd');
            }} 
            style={styles.closeButton}
          >
            <Text style={styles.closeIcon}>‚úï</Text>
          </TouchableOpacity>
          <TouchableOpacity 
            style={styles.minimizeButton}
            onPress={() => triggerHapticFeedback()}
          >
            <Text style={styles.minimizeIcon}>‚§ì</Text>
          </TouchableOpacity>
        </View>

        {/* Message d'erreur API si la cl√© n'est pas configur√©e */}
        {apiError && (
          <View style={styles.errorContainer}>
            <Text style={styles.errorText}>‚ö†Ô∏è {apiError}</Text>
            <Text style={styles.errorSubtext}>
              V√©rifiez votre fichier .env et red√©marrez le serveur Expo
            </Text>
          </View>
        )}

        {/* Texte de l'utilisateur ou salutation en haut */}
        {(showGreeting || userTranscription) && (
          <View style={styles.topTextContainer}>
            {userTranscription ? (
              <TypewriterText
                text={userTranscription}
                speed={50}
                style={styles.topText}
              />
            ) : (
              <Text style={styles.topText}>
                Hola{showGreetingPart2 ? ', ¬øc√≥mo est√°s?' : ''}
              </Text>
            )}
          </View>
        )}

        {/* Messages - seulement les messages de l'IA (pas les messages utilisateur) */}
        <ScrollView
          style={styles.messagesContainer}
          contentContainerStyle={styles.messagesContent}
          showsVerticalScrollIndicator={false}
        >
          {messages
            .filter((message) => !message.isUser) // Filtrer les messages utilisateur
            .map((message) => (
              <SpeechBubble
                key={message.id}
                text={message.text}
                isUser={message.isUser}
                translation={message.translation}
                explanation={message.explanation}
                textOnly={!message.isUser} // Texte seulement pour les messages de l'IA
              />
            ))}
        </ScrollView>

        {/* Microphone Button Only */}
        <View style={styles.microphoneContainer}>
          <TouchableOpacity
            style={styles.microphoneButtonContainer}
            onPress={handleMicrophonePress}
          >
            <MicrophoneButton
              listening={listening}
              onPress={handleMicrophonePress}
              size={60}
            />
          </TouchableOpacity>
        </View>
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: colors.backgroundDark,
    borderWidth: 0,
    borderColor: 'transparent',
    overflow: 'hidden',
    borderRadius: 0,
  },
  videoWrapper: {
    position: 'absolute',
    top: 0,
    left: 0,
    right: 0,
    bottom: 0,
    width: '100%',
    height: '100%',
    zIndex: 0,
    borderWidth: 0,
    borderColor: 'transparent',
    overflow: 'hidden',
  },
  videoContainer: {
    position: 'absolute',
    top: 0,
    left: 0,
    right: 0,
    bottom: 0,
    width: '100%',
    height: '100%',
  },
  standingVideoContainer: {
    zIndex: 0, // Derri√®re hola qui a zIndex: 1
  },
  backgroundVideo: {
    position: 'absolute',
    top: 0,
    left: 0,
    right: 0,
    bottom: 0,
    width: '100%',
    height: '100%',
    borderWidth: 0,
    borderColor: 'transparent',
  },
  videoHidden: {
    opacity: 0,
  },
  videoBehind: {
    zIndex: 0, // Derri√®re hola
    opacity: 1, // Toujours visible mais derri√®re
  },
  overlay: {
    position: 'absolute',
    top: 0,
    left: 0,
    right: 0,
    bottom: 0,
    backgroundColor: 'rgba(0, 0, 0, 0.1)',
    zIndex: 0,
  },
  borderMask: {
    position: 'absolute',
    top: 0,
    left: 0,
    right: 0,
    bottom: 0,
    borderWidth: 0,
    borderColor: 'transparent',
    zIndex: 999,
    pointerEvents: 'none',
  },
  content: {
    flex: 1,
    zIndex: 1,
    borderWidth: 0,
    borderColor: 'transparent',
  },
  header: {
    flexDirection: 'row',
    justifyContent: 'space-between',
    alignItems: 'center',
    paddingHorizontal: spacing.md,
    paddingTop: spacing.md,
    paddingBottom: spacing.sm,
  },
  closeButton: {
    width: 32,
    height: 32,
    borderRadius: 16,
    backgroundColor: colors.card,
    alignItems: 'center',
    justifyContent: 'center',
  },
  closeIcon: {
    fontSize: 18,
    color: colors.text,
    fontWeight: '600',
    fontFamily: typography.fontFamily.bold,
  },
  minimizeButton: {
    width: 32,
    height: 32,
    borderRadius: 16,
    backgroundColor: colors.card,
    alignItems: 'center',
    justifyContent: 'center',
  },
  minimizeIcon: {
    fontSize: 18,
    color: colors.text,
    fontFamily: typography.fontFamily.bold,
  },
  topTextContainer: {
    paddingHorizontal: spacing.md,
    paddingTop: spacing.sm,
    paddingBottom: spacing.md,
    alignItems: 'flex-start',
  },
  topText: {
    fontSize: typography.fontSize['2xl'],
    fontWeight: '900',
    color: colors.textWhite,
    fontFamily: typography.fontFamily.bold,
    textAlign: 'left',
    shadowColor: '#000000',
    shadowOffset: { width: 0, height: 2 },
    shadowOpacity: 0.5,
    shadowRadius: 4,
    elevation: 5,
  },
  messagesContainer: {
    flex: 1,
  },
  messagesContent: {
    padding: spacing.md,
    gap: spacing.sm,
  },
  microphoneContainer: {
    alignItems: 'center',
    justifyContent: 'center',
    paddingVertical: spacing.xl,
    paddingBottom: spacing.xl * 2, // Espace pour √©viter la navbar
  },
  microphoneButtonContainer: {
    alignItems: 'center',
    justifyContent: 'center',
  },
  errorContainer: {
    backgroundColor: 'rgba(255, 107, 53, 0.9)',
    marginHorizontal: spacing.md,
    marginTop: spacing.sm,
    padding: spacing.md,
    borderRadius: borderRadius.md,
    borderWidth: 1,
    borderColor: '#FF6B35',
  },
  errorText: {
    fontSize: typography.fontSize.base,
    fontWeight: typography.fontWeight.bold,
    color: colors.textWhite,
    fontFamily: typography.fontFamily.bold,
    marginBottom: spacing.xs,
  },
  errorSubtext: {
    fontSize: typography.fontSize.sm,
    color: colors.textWhite,
    fontFamily: typography.fontFamily.regular,
    opacity: 0.9,
  },
});
