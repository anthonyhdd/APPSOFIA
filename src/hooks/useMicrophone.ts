import { useState, useCallback, useRef } from 'react';
import { Alert, Platform } from 'react-native';
import { Audio } from 'expo-av';
import * as FileSystem from 'expo-file-system';

interface UseMicrophoneReturn {
  listening: boolean;
  startListening: () => Promise<void>;
  startListeningWithAutoStop: (validateCallback: (text: string | undefined | null) => Promise<boolean>) => Promise<void>;
  stopListening: () => Promise<string>;
  transcript: string;
  error: string | null;
  hasPermission: boolean;
  requestPermission: () => Promise<boolean>;
}

// Configuration de l'API de transcription
// Vous pouvez utiliser l'API Whisper d'OpenAI (gratuite jusqu'√† une limite)
// ou une autre API open source
const TRANSCRIPTION_API_URL = 'https://api.openai.com/v1/audio/transcriptions';
const TRANSCRIPTION_API_KEY = process.env.EXPO_PUBLIC_OPENAI_API_KEY || '';

// Debug: V√©rifier si la cl√© API est charg√©e
if (__DEV__) {
  console.log('üîë API Key loaded:', TRANSCRIPTION_API_KEY ? 'YES (length: ' + TRANSCRIPTION_API_KEY.length + ')' : 'NO');
  console.log('üîë API Key first 10 chars:', TRANSCRIPTION_API_KEY ? TRANSCRIPTION_API_KEY.substring(0, 10) + '...' : 'N/A');
  console.log('üîë API URL:', TRANSCRIPTION_API_URL);
}

// Alternative: Utiliser une API locale ou un service h√©berg√©
// Exemple avec un service Whisper h√©berg√© (gratuit):
// const TRANSCRIPTION_API_URL = 'https://your-whisper-api.com/transcribe';

export function useMicrophone(): UseMicrophoneReturn {
  const [listening, setListening] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [error, setError] = useState<string | null>(null);
  const [hasPermission, setHasPermission] = useState(false);
  const recordingRef = useRef<Audio.Recording | null>(null);
  const uriRef = useRef<string | null>(null);
  const validationIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const validateCallbackRef = useRef<((text: string | undefined | null) => Promise<boolean>) | null>(null);
  const inactivityTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const isCreatingRecordingRef = useRef<boolean>(false); // Verrou pour √©viter les cr√©ations simultan√©es

  const requestPermission = useCallback(async (): Promise<boolean> => {
    try {
      console.log('üé§ Requesting microphone permission...');
      const { status } = await Audio.requestPermissionsAsync();
      console.log('üé§ Permission status:', status);
      
      const granted = status === 'granted';
      setHasPermission(granted);
      
      if (!granted) {
        console.log('‚ùå Microphone permission denied');
        Alert.alert(
          'Permission requise',
          'L\'application a besoin d\'acc√©der au microphone pour fonctionner. Veuillez activer la permission dans les param√®tres de votre appareil.',
          [
            { text: 'Annuler', style: 'cancel' },
            { text: 'OK', style: 'default' },
          ]
        );
      } else {
        console.log('‚úÖ Microphone permission granted');
      }
      
      return granted;
    } catch (err) {
      console.error('‚ùå Error requesting permission:', err);
      const errorMsg = err instanceof Error ? err.message : 'Erreur lors de la demande de permission';
      setError(errorMsg);
      Alert.alert('Erreur', errorMsg);
      return false;
    }
  }, []);

  // Helper function to safely stop and unload a recording
  const safelyStopAndUnloadRecording = useCallback(async (
    recording: Audio.Recording
  ): Promise<string | null> => {
    try {
      // Get URI before unloading (once unloaded, getURI() returns null)
      const uri = recording.getURI();
      
      // Try to stop and unload
      try {
        await recording.stopAndUnloadAsync();
        console.log('‚úÖ Recording stopped and unloaded successfully');
      } catch (stopError: any) {
        // Check if error is because recording is already unloaded
        const errorMessage = stopError?.message || String(stopError);
        if (errorMessage.includes('already been unloaded') || 
            errorMessage.includes('unloaded') ||
            errorMessage.includes('not loaded')) {
          console.log('‚ö†Ô∏è Recording already unloaded, skipping stopAndUnloadAsync');
        } else {
          // Re-throw if it's a different error
          throw stopError;
        }
      }
      
      return uri;
    } catch (err) {
      console.error('‚ùå Error in safelyStopAndUnloadRecording:', err);
      return null;
    }
  }, []);

  // Fonction pour cr√©er un nouvel enregistrement de mani√®re s√©curis√©e
  const createRecordingSafely = useCallback(async (): Promise<Audio.Recording | null> => {
    // V√©rifier le verrou
    if (isCreatingRecordingRef.current) {
      console.log('‚ö†Ô∏è Already creating a recording, skipping...');
      return null;
    }

    // V√©rifier qu'il n'y a pas d'enregistrement en cours
    if (recordingRef.current) {
      console.log('‚ö†Ô∏è Recording already exists, cleaning up first...');
      const uri = await safelyStopAndUnloadRecording(recordingRef.current);
      if (uri) {
        try {
          await FileSystem.deleteAsync(uri, { idempotent: true });
        } catch (e) {
          // Ignorer les erreurs de suppression
        }
      }
      recordingRef.current = null;
    }

    // Activer le verrou
    isCreatingRecordingRef.current = true;

    try {
      console.log('üéôÔ∏è Creating new recording...');
      const { recording } = await Audio.Recording.createAsync(
        Audio.RecordingOptionsPresets.HIGH_QUALITY
      );
      console.log('‚úÖ Recording created successfully');
      return recording;
    } catch (err) {
      console.error('‚ùå Error creating recording:', err);
      return null;
    } finally {
      // D√©sactiver le verrou
      isCreatingRecordingRef.current = false;
    }
  }, [safelyStopAndUnloadRecording]);

  const transcribeAudio = useCallback(async (audioUri: string): Promise<string> => {
    try {
      console.log('üåê Starting transcription with API...');
      
      // Si vous utilisez l'API OpenAI Whisper
      if (!TRANSCRIPTION_API_KEY || TRANSCRIPTION_API_KEY.trim() === '') {
        console.error('‚ùå TRANSCRIPTION_API_KEY is missing or empty');
        console.error('‚ùå Check your .env file and ensure EXPO_PUBLIC_OPENAI_API_KEY is set');
        throw new Error('Cl√© API OpenAI non configur√©e. V√©rifiez votre fichier .env et red√©marrez l\'app.');
      }
      
      console.log('‚úÖ API Key is present, length:', TRANSCRIPTION_API_KEY.length);

      console.log('üì§ Preparing FormData...');
      // Cr√©er le FormData pour React Native
      const formData = new FormData();
      formData.append('file', {
        uri: audioUri,
        type: 'audio/m4a',
        name: 'recording.m4a',
      } as any);
      formData.append('model', 'whisper-1');
      // Ne pas sp√©cifier la langue pour laisser Whisper d√©tecter automatiquement
      // Cela permet de comprendre l'espagnol avec diff√©rents accents
      // formData.append('language', 'es'); // Optionnel : forcer l'espagnol si n√©cessaire

      console.log('üì° Sending request to OpenAI API...');
      const response = await fetch(TRANSCRIPTION_API_URL, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${TRANSCRIPTION_API_KEY}`,
          // Ne pas d√©finir Content-Type, laisse React Native le faire pour FormData
        },
        body: formData,
      });

      console.log('üì• Response status:', response.status);

      if (!response.ok) {
        const errorText = await response.text();
        console.error('‚ùå API Error:', response.status, errorText);
        throw new Error(`API Error (${response.status}): ${errorText}`);
      }

      const data = await response.json();
      console.log('‚úÖ Transcription successful:', data.text);
      return data.text || '';
    } catch (err) {
      console.error('‚ùå Transcription error:', err);
      throw err;
    }
  }, []);

  const startListening = useCallback(async () => {
    try {
      console.log('üé§ Starting to listen...');
      setError(null);
      setTranscript('');

      // V√©rifier et demander la permission
      if (!hasPermission) {
        console.log('‚ö†Ô∏è No permission, requesting...');
        const granted = await requestPermission();
        if (!granted) {
          console.log('‚ùå Permission not granted, cannot start recording');
          Alert.alert('Permission requise', 'Vous devez autoriser l\'acc√®s au microphone pour utiliser cette fonctionnalit√©.');
          return;
        }
      }

      console.log('üîß Configuring audio mode...');
      // Configurer le mode audio
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
      });

      console.log('üéôÔ∏è Creating recording...');
      // Cr√©er un nouvel enregistrement de mani√®re s√©curis√©e
      const recording = await createRecordingSafely();
      if (!recording) {
        throw new Error('Impossible de cr√©er l\'enregistrement');
      }

      recordingRef.current = recording;
      setListening(true);
      console.log('‚úÖ Recording started successfully');
    } catch (err) {
      console.error('‚ùå Error starting recording:', err);
      const errorMsg = err instanceof Error ? err.message : 'Erreur lors du d√©marrage de l\'enregistrement';
      setError(errorMsg);
      setListening(false);
      isCreatingRecordingRef.current = false; // Lib√©rer le verrou en cas d'erreur
      Alert.alert('Erreur', `Impossible de d√©marrer l'enregistrement: ${errorMsg}`);
    }
  }, [hasPermission, requestPermission, createRecordingSafely]);

  const stopListening = useCallback(async (): Promise<string> => {
    try {
      console.log('üõë Stopping recording...');
      
      // Arr√™ter l'intervalle de validation si actif
      if (validationIntervalRef.current) {
        clearInterval(validationIntervalRef.current);
        validationIntervalRef.current = null;
      }
      // Arr√™ter le timeout d'inactivit√© si actif
      if (inactivityTimeoutRef.current) {
        clearTimeout(inactivityTimeoutRef.current);
        inactivityTimeoutRef.current = null;
      }
      validateCallbackRef.current = null;
      
      if (!recordingRef.current) {
        console.log('‚ö†Ô∏è No recording to stop');
        return '';
      }

      setListening(false);

      // Arr√™ter l'enregistrement de mani√®re s√©curis√©e
      console.log('‚èπÔ∏è Stopping and unloading recording...');
      const recording = recordingRef.current;
      recordingRef.current = null; // Lib√©rer la r√©f√©rence imm√©diatement
      
      const uri = await safelyStopAndUnloadRecording(recording);
      
      if (!uri) {
        throw new Error('Aucun fichier audio enregistr√©');
      }

      console.log('üìÅ Audio file saved at:', uri);
      uriRef.current = uri;

      // V√©rifier que la cl√© API est pr√©sente
      if (!TRANSCRIPTION_API_KEY) {
        throw new Error('Cl√© API OpenAI non configur√©e. V√©rifiez votre fichier .env');
      }

      // Transcrire l'audio
      console.log('üîÑ Transcribing audio...');
      const transcribedText = await transcribeAudio(uri);
      console.log('‚úÖ Transcription result:', transcribedText);
      setTranscript(transcribedText);

      // Optionnel: Supprimer le fichier temporaire
      try {
        await FileSystem.deleteAsync(uri, { idempotent: true });
        console.log('üóëÔ∏è Temp file deleted');
      } catch (deleteErr) {
        // Ignorer les erreurs de suppression
        console.log('‚ö†Ô∏è Could not delete temp file:', deleteErr);
      }

      return transcribedText;
    } catch (err) {
      console.error('‚ùå Error stopping recording:', err);
      const errorMessage = err instanceof Error ? err.message : 'Erreur lors de l\'arr√™t de l\'enregistrement';
      setError(errorMessage);
      setListening(false);
      Alert.alert('Erreur', errorMessage);
      return '';
    }
  }, [transcribeAudio, safelyStopAndUnloadRecording]);

  // Fonction pour transcrire un segment d'audio sans arr√™ter l'enregistrement
  const transcribeCurrentSegment = useCallback(async (): Promise<string | null> => {
    try {
      if (!recordingRef.current) {
        return null;
      }

      // Cr√©er une copie temporaire de l'enregistrement actuel
      const tempUri = recordingRef.current.getURI();
      if (!tempUri) {
        return null;
      }

      // Pour transcrire un segment, on doit d'abord arr√™ter temporairement
      // Puis reprendre. Mais avec expo-av, on ne peut pas faire √ßa facilement.
      // Solution: on va cr√©er un nouvel enregistrement √† chaque fois
      // et fusionner les segments, ou mieux: on va attendre un peu puis transcrire
      
      // Pour l'instant, on va transcrire l'audio actuel
      // Note: Cette approche n√©cessite d'arr√™ter l'enregistrement
      // Une meilleure solution serait d'utiliser un buffer audio
      
      return null;
    } catch (err) {
      console.error('Error transcribing segment:', err);
      return null;
    }
  }, []);


  // Fonction pour valider p√©riodiquement pendant l'enregistrement
  const validatePeriodically = useCallback(async () => {
    // V√©rifier que l'enregistrement est toujours actif et que le callback existe
    if (!recordingRef.current || !validateCallbackRef.current) {
      console.log('‚ö†Ô∏è No recording or callback, stopping validation');
      if (validationIntervalRef.current) {
        clearInterval(validationIntervalRef.current);
        validationIntervalRef.current = null;
      }
      return;
    }

    // V√©rifier le verrou avant de continuer
    if (isCreatingRecordingRef.current) {
      console.log('‚ö†Ô∏è Already processing, skipping validation cycle...');
      return;
    }

    try {
      console.log('üîç Checking for valid answer...');
      
      // Arr√™ter temporairement l'enregistrement pour transcrire
      const recording = recordingRef.current;
      recordingRef.current = null; // Lib√©rer la r√©f√©rence imm√©diatement
      
      // Arr√™ter l'enregistrement de mani√®re s√©curis√©e
      const uri = await safelyStopAndUnloadRecording(recording);
      
      if (!uri) {
        console.log('‚ö†Ô∏è No URI from recording, creating new one...');
        // Reprendre l'enregistrement
        const newRecording = await createRecordingSafely();
        if (newRecording) {
          recordingRef.current = newRecording;
        }
        return;
      }

      // Transcrire le segment
      let transcribedText: string | undefined;
      try {
        transcribedText = await transcribeAudio(uri);
        console.log('üîç Current transcription:', transcribedText);
      } catch (transcribeError) {
        console.error('‚ùå Error transcribing audio:', transcribeError);
        transcribedText = undefined;
      }

      // Supprimer le fichier temporaire apr√®s transcription
      try {
        await FileSystem.deleteAsync(uri, { idempotent: true });
      } catch (e) {
        // Ignorer
      }

      if (transcribedText && typeof transcribedText === 'string' && transcribedText.trim().length > 0 && validateCallbackRef.current) {
        // Valider avec le callback
        try {
          const isValid = await validateCallbackRef.current(transcribedText);
          
          if (isValid) {
            console.log('‚úÖ Valid answer detected! Stopping automatically...');
            // Arr√™ter l'intervalle
            if (validationIntervalRef.current) {
              clearInterval(validationIntervalRef.current);
              validationIntervalRef.current = null;
            }
            // Arr√™ter le timeout d'inactivit√©
            if (inactivityTimeoutRef.current) {
              clearTimeout(inactivityTimeoutRef.current);
              inactivityTimeoutRef.current = null;
            }
            
            // Mettre √† jour le transcript
            setTranscript(transcribedText);
            setListening(false);
            
            // Nettoyer
            recordingRef.current = null;
            validateCallbackRef.current = null;
            
            return;
          }
        } catch (callbackError) {
          console.error('‚ùå Error in validation callback:', callbackError);
          // Continuer l'enregistrement m√™me si le callback √©choue
        }
      }

      // Si pas valide, reprendre l'enregistrement
      console.log('‚è© Answer not valid yet, continuing...');
      const newRecording = await createRecordingSafely();
      if (newRecording) {
        recordingRef.current = newRecording;
      }
      
    } catch (err) {
      console.error('Error in periodic validation:', err);
      // En cas d'erreur, essayer de reprendre l'enregistrement
      // Ne pas propager l'erreur pour √©viter de casser l'enregistrement
      try {
        const newRecording = await createRecordingSafely();
        if (newRecording) {
          recordingRef.current = newRecording;
        }
      } catch (recoveryErr) {
        console.error('Error recovering from validation error:', recoveryErr);
        // Ne rien faire, juste logger l'erreur
      }
    }
  }, [transcribeAudio, createRecordingSafely, safelyStopAndUnloadRecording]);

  const startListeningWithAutoStop = useCallback(async (
    validateCallback: (text: string | undefined | null) => Promise<boolean>
  ) => {
    try {
      console.log('üé§ Starting to listen with auto-stop...');
      setError(null);
      setTranscript('');

      // Sauvegarder le callback de validation
      validateCallbackRef.current = validateCallback;

      // V√©rifier et demander la permission
      if (!hasPermission) {
        console.log('‚ö†Ô∏è No permission, requesting...');
        const granted = await requestPermission();
        if (!granted) {
          console.log('‚ùå Permission not granted, cannot start recording');
          Alert.alert('Permission requise', 'Vous devez autoriser l\'acc√®s au microphone pour utiliser cette fonctionnalit√©.');
          return;
        }
      }

      console.log('üîß Configuring audio mode...');
      // Configurer le mode audio
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
      });

      console.log('üéôÔ∏è Creating recording...');
      // Cr√©er un nouvel enregistrement de mani√®re s√©curis√©e
      const recording = await createRecordingSafely();
      if (!recording) {
        throw new Error('Impossible de cr√©er l\'enregistrement');
      }

      recordingRef.current = recording;
      setListening(true);
      console.log('‚úÖ Recording started successfully');

      // D√©marrer la validation p√©riodique (toutes les 2 secondes)
      validationIntervalRef.current = setInterval(() => {
        validatePeriodically();
      }, 2000);

      // Timeout d'inactivit√© : arr√™ter apr√®s 30 secondes sans validation r√©ussie
      inactivityTimeoutRef.current = setTimeout(async () => {
        console.log('‚è±Ô∏è Inactivity timeout: stopping microphone');
        if (recordingRef.current) {
          const recording = recordingRef.current;
          recordingRef.current = null;
          const uri = await safelyStopAndUnloadRecording(recording);
          if (uri) {
            try { 
              await FileSystem.deleteAsync(uri, { idempotent: true }); 
            } catch (e) {
              // Ignorer les erreurs de suppression
            }
          }
        }
        if (validationIntervalRef.current) {
          clearInterval(validationIntervalRef.current);
          validationIntervalRef.current = null;
        }
        validateCallbackRef.current = null;
        setListening(false);
        setError('Enregistrement arr√™t√© apr√®s 30 secondes d\'inactivit√©');
      }, 30000); // 30 secondes
      
    } catch (err) {
      console.error('‚ùå Error starting recording:', err);
      const errorMsg = err instanceof Error ? err.message : 'Erreur lors du d√©marrage de l\'enregistrement';
      setError(errorMsg);
      setListening(false);
      isCreatingRecordingRef.current = false; // Lib√©rer le verrou en cas d'erreur
      Alert.alert('Erreur', `Impossible de d√©marrer l'enregistrement: ${errorMsg}`);
    }
  }, [hasPermission, requestPermission, validatePeriodically, createRecordingSafely, safelyStopAndUnloadRecording]);

  return {
    listening,
    startListening,
    startListeningWithAutoStop,
    stopListening,
    transcript,
    error,
    hasPermission,
    requestPermission,
  };
}
